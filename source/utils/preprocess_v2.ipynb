{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing v2\n",
    "\n",
    "### Steps:\n",
    "\n",
    "1. **Load Datasets:**\n",
    "   - Load 'charts_processed.csv'.\n",
    "\n",
    "2. **Align Datasets:**\n",
    "   - Rename 'id' in audio features to 'track_id'.\n",
    "   - Keep only top 200 chart entries.\n",
    "\n",
    "3. **Add Columns:**\n",
    "   - Extract 'track_id' from chart URLs.\n",
    "\n",
    "4. **Remove Columns:**\n",
    "   - Drop unnecessary columns ('url', 'chart', 'trend').\n",
    "\n",
    "5. **Calculate Streams Percentage:**\n",
    "   - Create 'streams_percentage' in charts.\n",
    "   - Calculate percentage for each row.\n",
    "\n",
    "6. **Validate Data:**\n",
    "   - Check if sampled date-region 'streams_percentage' sums close to 1.0.\n",
    "\n",
    "7. **Save CSV:**\n",
    "   - Save preprocessed data as 'charts_processed_v2.csv'.\n",
    "\n",
    "Note: This version ensures dataset alignment, calculates streams percentage and validates data integrity. The result is saved for future use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KAGGLE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if KAGGLE:\n",
    "    CHARTS_PATH = '/kaggle/input/regionalrhythms/charts_processed.csv'\n",
    "    PATH_TO_SAVE = '/kaggle/working/'\n",
    "else:\n",
    "    CHARTS_PATH = \"../../data/charts_processed.csv\"\n",
    "    PATH_TO_SAVE = \"../../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets into dataframes\n",
    "charts_df = pd.read_csv(CHARTS_PATH, parse_dates=['date'], date_format='%Y-%m-%d')\n",
    "charts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now only restrict the dataset to top200 charts for stream/ranking analysis.\n",
    "charts_df = charts_df[charts_df[\"chart\"] == \"top200\"]\n",
    "charts_df[\"track_id\"] = charts_df[\"url\"].apply(lambda x: x.split(\"/\")[-1])\n",
    "\n",
    "# drop the url, chart and trend columns\n",
    "charts_df.drop(columns=[\"url\", \"chart\", \"trend\"], inplace=True)\n",
    "\n",
    "# Create a new column for streams_percentage\n",
    "charts_df['streams_percentage'] = 0.0\n",
    "\n",
    "# Create a dictionary to store total streams for each region-date combination\n",
    "total_streams_dict = {}\n",
    "\n",
    "# Populate the dictionary\n",
    "for (region, date), group in tqdm(charts_df.groupby(['region', 'date'])):\n",
    "    total_streams_dict[(region, date)] = group['streams'].sum()\n",
    "\n",
    "charts_df['streams_percentage'] = charts_df.progress_apply(lambda row: row['streams'] / total_streams_dict.get((row['region'], row['date']), 0), axis=1)\n",
    "\n",
    "charts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first build 200 date-region combinations\n",
    "date_region_combinations = list(charts_df.groupby([\"date\", \"region\"]).groups.keys())\n",
    "\n",
    "# sample 200 combinations\n",
    "indices = np.random.choice(len(date_region_combinations), 200)\n",
    "sampled_date_region_combinations = [date_region_combinations[i] for i in indices]\n",
    "\n",
    "# check if the streams_percentage adds up to 1, dont worry about the rounding errors print if the sum is not 1\n",
    "for date, region in tqdm(sampled_date_region_combinations):\n",
    "    df = charts_df[(charts_df[\"date\"] == date) & (charts_df[\"region\"] == region)]\n",
    "    if not np.isclose(df[\"streams_percentage\"].sum(), 1.0):\n",
    "        print(\"Sum is not 1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the csv file\n",
    "charts_df.to_csv(PATH_TO_SAVE + \"charts_processed_v2.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
